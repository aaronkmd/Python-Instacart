{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cc329b4-9cdb-4c16-92ea-81d7f116e1b3",
   "metadata": {},
   "source": [
    "# Exercise 4.9 PART 1: Intro to Data Visualization with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716b3cd9-7873-4beb-8650-f8fc33e4854f",
   "metadata": {},
   "source": [
    "## Contents:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b4d038-0a2e-4543-9882-ee79dc119d63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "    0. Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61025875-c6f9-441d-8300-d381e2f211df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "    1. Loading and Checking the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1912f2ef-1c6e-4d6b-908c-5fccd7519e86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "    2. Wrangling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f0228e-ca27-4d92-a2a4-d191721caf0e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "    3. Data Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac03ebf2-7d1f-4bc9-b8c9-ed17aed3a4e2",
   "metadata": {},
   "source": [
    "    4. Combining Customer Data with Previously Prepared Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d9e5f9-9874-4ae8-a737-58627cfaf7ef",
   "metadata": {},
   "source": [
    "    5. Export the New Dataframe as a Pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e2f49e-7dda-471f-a029-944856693a91",
   "metadata": {},
   "source": [
    "## 0. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ff843cd-fe45-4aa4-a59e-dacf80a84544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dbbf14-2bc5-44f4-a51c-c9cca368a5f7",
   "metadata": {},
   "source": [
    "## 1. Loading and Checking the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0958dc47-2553-462d-9321-6bed4922786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data files\n",
    "path = '/Users/aaronkibler/CF Project 4 - Instacart Basket Analysis/02 Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34b5ff2f-e8ae-4eac-9daf-cd8138de9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load \"customers.csv\" from the \"Original Data\" folder as \"df_customers\"\n",
    "df_customers = pd.read_csv(os.path.join(path, 'Original Data', 'customers.csv'), index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dda49833-6acd-49c0-90e9-1709e225dacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id First Name    Surnam  Gender       STATE  Age date_joined  \\\n",
      "0    26711    Deborah  Esquivel  Female    Missouri   48    1/1/2017   \n",
      "1    33890   Patricia      Hart  Female  New Mexico   36    1/1/2017   \n",
      "2    65803    Kenneth    Farley    Male       Idaho   35    1/1/2017   \n",
      "3   125935   Michelle     Hicks  Female        Iowa   40    1/1/2017   \n",
      "4   130797        Ann   Gilmore  Female    Maryland   26    1/1/2017   \n",
      "\n",
      "   n_dependants fam_status  income  \n",
      "0             3    married  165665  \n",
      "1             0     single   59285  \n",
      "2             2    married   99568  \n",
      "3             0     single   42049  \n",
      "4             1    married   40374  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 206209 entries, 0 to 206208\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   user_id       206209 non-null  int64 \n",
      " 1   First Name    194950 non-null  object\n",
      " 2   Surnam        206209 non-null  object\n",
      " 3   Gender        206209 non-null  object\n",
      " 4   STATE         206209 non-null  object\n",
      " 5   Age           206209 non-null  int64 \n",
      " 6   date_joined   206209 non-null  object\n",
      " 7   n_dependants  206209 non-null  int64 \n",
      " 8   fam_status    206209 non-null  object\n",
      " 9   income        206209 non-null  int64 \n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 15.7+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(206209, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking \"customers.csv\" data is correctly loaded\n",
    "print(df_customers.head())\n",
    "print(df_customers.info())\n",
    "df_customers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e792a59a-4973-4c5d-8021-91db52b3db01",
   "metadata": {},
   "source": [
    "## 2. Wrangling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe6a83a-af32-4f95-8a68-9dcc2579d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns for consistency and clarity\n",
    "df_customers.rename(columns={'First Name': 'first_name', 'Surnam': 'surname', 'Gender': 'gender', 'STATE': 'state', 'Age': 'age', 'n_dependants': 'dependants', 'fam_status': 'family_status', 'income': 'income'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4aec527-166f-4bb0-99a0-1597831b2a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'first_name', 'surname', 'gender', 'state', 'age',\n",
      "       'date_joined', 'dependants', 'family_status', 'income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Verify the names of the columns after making changes\n",
    "print(df_customers.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82cc4062-48f4-4003-b3d8-9c82c4c3e7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id           int64\n",
      "first_name       object\n",
      "surname          object\n",
      "gender           object\n",
      "state            object\n",
      "age               int64\n",
      "date_joined      object\n",
      "dependants        int64\n",
      "family_status    object\n",
      "income            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types and make adjustments as needed\n",
    "print(df_customers.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1fc584f-c19e-417b-9105-a032e8299fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"user_id\" data type to \"string\"\n",
    "df_customers['user_id'] = df_customers['user_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "697eb14e-c9de-4f4a-9c7c-ec78cc09caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"date_joined\" to data type datetime\n",
    "df_customers['date_joined'] = pd.to_datetime(df_customers['date_joined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0c4d18a-be7b-449d-9aae-c9d128403e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id                  object\n",
      "first_name               object\n",
      "surname                  object\n",
      "gender                   object\n",
      "state                    object\n",
      "age                       int64\n",
      "date_joined      datetime64[ns]\n",
      "dependants                int64\n",
      "family_status            object\n",
      "income                    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Recheck data types after making changes\n",
    "print(df_customers.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b867e2f-ab61-4b37-9960-a87f22f3caaa",
   "metadata": {},
   "source": [
    "## 3. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52a14671-2973-404b-b829-c423d2b9cae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(\"Duplicates:\", df_customers.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b5faa62-e86d-4bdd-9cb4-1504d55f221f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_name\n"
     ]
    }
   ],
   "source": [
    "# Check for mixed data types in each column\n",
    "for col in df_customers.columns.tolist():\n",
    "    weird = (df_customers[[col]].map(type) != df_customers[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "    if len (df_customers[weird]) > 0:\n",
    "        print (col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff79011d-cc62-45f1-8454-ddc3149c3dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"first_name\" column should have a data type \"string\"\n",
    "df_customers['first_name'] = df_customers['first_name'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58c11140-8710-4d27-9d5b-f22a65d10a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id                  object\n",
      "first_name               object\n",
      "surname                  object\n",
      "gender                   object\n",
      "state                    object\n",
      "age                       int64\n",
      "date_joined      datetime64[ns]\n",
      "dependants                int64\n",
      "family_status            object\n",
      "income                    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Recheck data types after making changes\n",
    "print(df_customers.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eba6cf7-edd8-48c5-a03d-2be6d4c37624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recheck for mixed data types\n",
    "for col in df_customers.columns.tolist():\n",
    "    weird = (df_customers[[col]].map(type) != df_customers[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "    if len (df_customers[weird]) > 0:\n",
    "        print (col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04597f78-3ce0-493d-b197-d20a4c9c57ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id          0\n",
      "first_name       0\n",
      "surname          0\n",
      "gender           0\n",
      "state            0\n",
      "age              0\n",
      "date_joined      0\n",
      "dependants       0\n",
      "family_status    0\n",
      "income           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df_customers.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fca80d5-ae9f-4f44-919a-7fb15bd1df5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>date_joined</th>\n",
       "      <th>dependants</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>206209.000000</td>\n",
       "      <td>206209</td>\n",
       "      <td>206209.000000</td>\n",
       "      <td>206209.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.501646</td>\n",
       "      <td>2018-08-17 03:06:30.029532928</td>\n",
       "      <td>1.499823</td>\n",
       "      <td>94632.852548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25903.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>2017-10-23 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59874.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>2018-08-16 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93547.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>2019-06-10 00:00:00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>124244.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>2020-04-01 00:00:00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>593901.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.480962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.118433</td>\n",
       "      <td>42473.786988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age                    date_joined     dependants  \\\n",
       "count  206209.000000                         206209  206209.000000   \n",
       "mean       49.501646  2018-08-17 03:06:30.029532928       1.499823   \n",
       "min        18.000000            2017-01-01 00:00:00       0.000000   \n",
       "25%        33.000000            2017-10-23 00:00:00       0.000000   \n",
       "50%        49.000000            2018-08-16 00:00:00       1.000000   \n",
       "75%        66.000000            2019-06-10 00:00:00       3.000000   \n",
       "max        81.000000            2020-04-01 00:00:00       3.000000   \n",
       "std        18.480962                            NaN       1.118433   \n",
       "\n",
       "              income  \n",
       "count  206209.000000  \n",
       "mean    94632.852548  \n",
       "min     25903.000000  \n",
       "25%     59874.000000  \n",
       "50%     93547.000000  \n",
       "75%    124244.000000  \n",
       "max    593901.000000  \n",
       "std     42473.786988  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the descriptive stats for anything unusal\n",
    "df_customers.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c7b491-3d54-4dfd-9c74-d964c34b884b",
   "metadata": {},
   "source": [
    "### All quality checks now appear okay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7825d7d6-a4ab-4a3a-84c8-bc94a075333e",
   "metadata": {},
   "source": [
    "## 4. Combining Customer Data with Previously Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f4f97e1-519d-46de-80f1-36e0fead4b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the most up-to-date version of the previously prepared data as \"df_ords_prods_new\"\n",
    "df_ords_prods_new = pd.read_pickle(os.path.join(path, 'Prepared Data', 'ords_prods_merge_new_var_group_agg.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5b0e60e-5deb-467d-b7e1-b12ffca77882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id                product_name  aisle_id  department_id  prices  \\\n",
      "0           1  Chocolate Sandwich Cookies        61             19     5.8   \n",
      "1           1  Chocolate Sandwich Cookies        61             19     5.8   \n",
      "2           1  Chocolate Sandwich Cookies        61             19     5.8   \n",
      "3           1  Chocolate Sandwich Cookies        61             19     5.8   \n",
      "4           1  Chocolate Sandwich Cookies        61             19     5.8   \n",
      "\n",
      "   order_id  user_id  order_number  orders_day_of_week  order_hour_of_day  \\\n",
      "0   3139998      138            28                   6                 11   \n",
      "1   1977647      138            30                   6                 17   \n",
      "2    389851      709             2                   0                 21   \n",
      "3    652770      764             1                   3                 13   \n",
      "4   1813452      764             3                   4                 17   \n",
      "\n",
      "   ...    price_range_loc     busiest_day  busiest_days  \\\n",
      "0  ...  Mid-range product  Regularly busy  Regular days   \n",
      "1  ...  Mid-range product  Regularly busy  Regular days   \n",
      "2  ...  Mid-range product     Busiest day  Busiest days   \n",
      "3  ...  Mid-range product  Regularly busy  Slowest days   \n",
      "4  ...  Mid-range product      Least busy  Slowest days   \n",
      "\n",
      "   busiest_period_of_day max_order      loyalty_flag mean_product_price  \\\n",
      "0            Most orders        32  Regular customer           6.935811   \n",
      "1         Average orders        32  Regular customer           6.935811   \n",
      "2         Average orders         5      New customer           7.930208   \n",
      "3            Most orders         3      New customer           4.972414   \n",
      "4         Average orders         3      New customer           4.972414   \n",
      "\n",
      "  spending_flag order_frequency     frequency_flag  \n",
      "0   Low_spender             8.0  Frequent customer  \n",
      "1   Low_spender             8.0  Frequent customer  \n",
      "2   Low_spender             8.0  Frequent customer  \n",
      "3   Low_spender             9.0  Frequent customer  \n",
      "4   Low_spender             9.0  Frequent customer  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32404859 entries, 0 to 32404858\n",
      "Data columns (total 25 columns):\n",
      " #   Column                  Dtype   \n",
      "---  ------                  -----   \n",
      " 0   product_id              int64   \n",
      " 1   product_name            object  \n",
      " 2   aisle_id                int64   \n",
      " 3   department_id           int64   \n",
      " 4   prices                  float64 \n",
      " 5   order_id                int64   \n",
      " 6   user_id                 int64   \n",
      " 7   order_number            int64   \n",
      " 8   orders_day_of_week      int64   \n",
      " 9   order_hour_of_day       int64   \n",
      " 10  days_since_prior_order  float64 \n",
      " 11  is_first_order          int64   \n",
      " 12  add_to_cart_order       int64   \n",
      " 13  reordered               int64   \n",
      " 14  _merge                  category\n",
      " 15  price_range_loc         object  \n",
      " 16  busiest_day             object  \n",
      " 17  busiest_days            object  \n",
      " 18  busiest_period_of_day   object  \n",
      " 19  max_order               int64   \n",
      " 20  loyalty_flag            object  \n",
      " 21  mean_product_price      float64 \n",
      " 22  spending_flag           object  \n",
      " 23  order_frequency         float64 \n",
      " 24  frequency_flag          object  \n",
      "dtypes: category(1), float64(4), int64(12), object(8)\n",
      "memory usage: 5.8+ GB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32404859, 25)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking \"ords_prods_merge_new_var_group_agg.pkl\" data is correctly loaded\n",
    "print(df_ords_prods_new.head())\n",
    "print(df_ords_prods_new.info())\n",
    "df_ords_prods_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fc1570-bde3-4284-858f-27da14cda123",
   "metadata": {},
   "source": [
    "### Both \"df_customers\" and \"df_ords_prods_new\" have a \"user_id\" column which we can use to merge the two datasets together.\n",
    "### \"user_id\" in the \"df_ords_prods_new\" dataframe must first be converted to \"string\" to match the \"user_id\" column in \"df_customers\"\n",
    "### At the same time, the other identifier columns in the dataframe can also be converted to \"string\"\n",
    "### Identifier columns to convert to \"string\": \"product_id\", \"aisle_id\", \"department_id\", \"order_id\", and \"user_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d646f21-593e-460f-818a-99547512db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the identifier columns in \"df_ords_prods_new\" to \"string\"\n",
    "df_ords_prods_new[['product_id', 'aisle_id', 'department_id', 'order_id', 'user_id']] = df_ords_prods_new[['product_id', 'aisle_id', 'department_id', 'order_id', 'user_id']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81c7ccd9-283c-4745-86b3-4bcaa3b153bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id                  object\n",
      "product_name                object\n",
      "aisle_id                    object\n",
      "department_id               object\n",
      "prices                     float64\n",
      "order_id                    object\n",
      "user_id                     object\n",
      "order_number                 int64\n",
      "orders_day_of_week           int64\n",
      "order_hour_of_day            int64\n",
      "days_since_prior_order     float64\n",
      "is_first_order               int64\n",
      "add_to_cart_order            int64\n",
      "reordered                    int64\n",
      "_merge                    category\n",
      "price_range_loc             object\n",
      "busiest_day                 object\n",
      "busiest_days                object\n",
      "busiest_period_of_day       object\n",
      "max_order                    int64\n",
      "loyalty_flag                object\n",
      "mean_product_price         float64\n",
      "spending_flag               object\n",
      "order_frequency            float64\n",
      "frequency_flag              object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the results of the change\n",
    "print(df_ords_prods_new.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fce9068-c3f7-42c4-b972-e7879181abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the existing \"_merge\" column from \"df_ords_prods_new\"\n",
    "df_ords_prods_new = df_ords_prods_new.drop(columns=['_merge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b082de69-69e4-4f9e-b53d-eee12dacc8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['product_id', 'product_name', 'aisle_id', 'department_id', 'prices',\n",
      "       'order_id', 'user_id', 'order_number', 'orders_day_of_week',\n",
      "       'order_hour_of_day', 'days_since_prior_order', 'is_first_order',\n",
      "       'add_to_cart_order', 'reordered', 'price_range_loc', 'busiest_day',\n",
      "       'busiest_days', 'busiest_period_of_day', 'max_order', 'loyalty_flag',\n",
      "       'mean_product_price', 'spending_flag', 'order_frequency',\n",
      "       'frequency_flag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the columns after the change\n",
    "print(df_ords_prods_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "991b0361-af97-4742-b69f-cd4dca650933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes using the default inner join\n",
    "df_final_merged = df_ords_prods_new.merge(df_customers, on='user_id', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83f24501-139b-42e7-9c11-8555f44bde90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_merge\n",
       "both          32404859\n",
       "left_only            0\n",
       "right_only           0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check \"value_counts\" after inner join\n",
    "df_final_merged['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b04fd73e-553d-4be6-8baa-33affea617fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product_id                product_name aisle_id department_id  prices  \\\n",
      "0          1  Chocolate Sandwich Cookies       61            19     5.8   \n",
      "1          1  Chocolate Sandwich Cookies       61            19     5.8   \n",
      "2        907        Premium Sliced Bacon      106            12    20.0   \n",
      "3        907        Premium Sliced Bacon      106            12    20.0   \n",
      "4       1000                    Apricots       18            10    12.9   \n",
      "\n",
      "  order_id user_id  order_number  orders_day_of_week  order_hour_of_day  ...  \\\n",
      "0  3139998     138            28                   6                 11  ...   \n",
      "1  1977647     138            30                   6                 17  ...   \n",
      "2  3160996     138             1                   5                 13  ...   \n",
      "3  2254091     138            10                   5                 14  ...   \n",
      "4   505689     138             9                   6                 12  ...   \n",
      "\n",
      "   first_name  surname  gender      state age date_joined dependants  \\\n",
      "0     Charles      Cox    Male  Minnesota  81  2019-08-01          1   \n",
      "1     Charles      Cox    Male  Minnesota  81  2019-08-01          1   \n",
      "2     Charles      Cox    Male  Minnesota  81  2019-08-01          1   \n",
      "3     Charles      Cox    Male  Minnesota  81  2019-08-01          1   \n",
      "4     Charles      Cox    Male  Minnesota  81  2019-08-01          1   \n",
      "\n",
      "  family_status  income _merge  \n",
      "0       married   49620   both  \n",
      "1       married   49620   both  \n",
      "2       married   49620   both  \n",
      "3       married   49620   both  \n",
      "4       married   49620   both  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32404859 entries, 0 to 32404858\n",
      "Data columns (total 34 columns):\n",
      " #   Column                  Dtype         \n",
      "---  ------                  -----         \n",
      " 0   product_id              object        \n",
      " 1   product_name            object        \n",
      " 2   aisle_id                object        \n",
      " 3   department_id           object        \n",
      " 4   prices                  float64       \n",
      " 5   order_id                object        \n",
      " 6   user_id                 object        \n",
      " 7   order_number            int64         \n",
      " 8   orders_day_of_week      int64         \n",
      " 9   order_hour_of_day       int64         \n",
      " 10  days_since_prior_order  float64       \n",
      " 11  is_first_order          int64         \n",
      " 12  add_to_cart_order       int64         \n",
      " 13  reordered               int64         \n",
      " 14  price_range_loc         object        \n",
      " 15  busiest_day             object        \n",
      " 16  busiest_days            object        \n",
      " 17  busiest_period_of_day   object        \n",
      " 18  max_order               int64         \n",
      " 19  loyalty_flag            object        \n",
      " 20  mean_product_price      float64       \n",
      " 21  spending_flag           object        \n",
      " 22  order_frequency         float64       \n",
      " 23  frequency_flag          object        \n",
      " 24  first_name              object        \n",
      " 25  surname                 object        \n",
      " 26  gender                  object        \n",
      " 27  state                   object        \n",
      " 28  age                     int64         \n",
      " 29  date_joined             datetime64[ns]\n",
      " 30  dependants              int64         \n",
      " 31  family_status           object        \n",
      " 32  income                  int64         \n",
      " 33  _merge                  category      \n",
      "dtypes: category(1), datetime64[ns](1), float64(4), int64(10), object(18)\n",
      "memory usage: 8.0+ GB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32404859, 34)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the details of the new \"df_final_merged\" dataframe\n",
    "print(df_final_merged.head())\n",
    "print(df_final_merged.info())\n",
    "df_final_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f8584e-1ada-4cbc-8c7a-720ec1b1dc8a",
   "metadata": {},
   "source": [
    "## 5. Export the New Dataframe as a Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25c5a12b-0483-4e95-9e89-0c6375879f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the \"df_final_merged\" dataframe as \"ords_prods_cust_merge\" for use in PART 2\n",
    "df_final_merged.to_pickle(os.path.join(path, 'Prepared Data', 'ords_prods_cust_merge.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb48f3-4a1f-4e23-90ae-2a1fb6d538b1",
   "metadata": {},
   "source": [
    "# End of Exercise 4.9 PART 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
